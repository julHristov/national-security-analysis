import json
from pathlib import Path
from collections import defaultdict
import spacy
from typing import Dict, List, Set, Tuple

from config import CLEAN_DIR, RESULTS_DIR
from utils.file_manager import read_text_file, write_json_file


class TermWeightExtractor:
    """–ö–ª–∞—Å –∑–∞ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∏ –∏ –∏–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ —Ç–µ—Ö–Ω–∏—Ç–µ —Ç–µ–≥–ª–∞ —Å–ø–æ—Ä–µ–¥ —á–µ—Å—Ç–æ—Ç–∞—Ç–∞."""
    
    def __init__(self, schema_dir: str = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞ –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º–∏—Ç–µ —Ä–µ—á–Ω–∏—Ü–∏."""
        if not schema_dir:
            schema_dir = Path(__file__).parent.parent / "schema"
            
        # –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ —Ä–µ—á–Ω–∏—Ü–∏—Ç–µ —Å —Ç–µ—Ä–º–∏–Ω–∏
        with open(schema_dir / "positive_terms.json", "r", encoding="utf-8") as f:
            self.positive_terms = set(json.load(f))
            
        with open(schema_dir / "negative_terms.json", "r", encoding="utf-8") as f:
            self.negative_terms = set(json.load(f))
            
        with open(schema_dir / "neutral_terms.json", "r", encoding="utf-8") as f:
            self.neutral_terms = set(json.load(f))
            
        # –†–µ—á–Ω–∏—Ü–∏ –∑–∞ —Å—ä—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ —á–µ—Å—Ç–æ—Ç–∏—Ç–µ
        self.term_frequencies = {
            "positive": defaultdict(int),
            "negative": defaultdict(int),
            "neutral": defaultdict(int)
        }
        
        # –†–µ—á–Ω–∏–∫ –∑–∞ —Å—ä—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ —Ç–µ–≥–ª–∞—Ç–∞
        self.term_weights = {
            "positive": {},
            "negative": {},
            "neutral": {}
        }
        
    def _get_term_type(self, term: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è —Ç–∏–ø–∞ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∞ (positive, negative, neutral)."""
        if term in self.positive_terms:
            return "positive"
        elif term in self.negative_terms:
            return "negative"
        elif term in self.neutral_terms:
            return "neutral"
        return None
        
    def extract_terms(self, text: str) -> Dict[str, List[Tuple[str, int]]]:
        """–ò–∑–≤–ª–∏—á–∞ —Ç–µ—Ä–º–∏–Ω–∏ –æ—Ç —Ç–µ–∫—Å—Ç–∞ –∏ –±—Ä–æ–∏ —á–µ—Å—Ç–æ—Ç–∞—Ç–∞ –∏–º."""
        text = text.lower()
        
        # –ò–∑–≤–ª–∏—á–∞–º–µ –≤—Å–∏—á–∫–∏ —Ç–µ—Ä–º–∏–Ω–∏ –∏ —á–µ—Å—Ç–æ—Ç–∏—Ç–µ –∏–º
        for term_type, terms in [
            ("positive", self.positive_terms),
            ("negative", self.negative_terms),
            ("neutral", self.neutral_terms)
        ]:
            for term in terms:
                count = text.count(term)
                if count > 0:
                    self.term_frequencies[term_type][term] += count
                    
        return {k: dict(v) for k, v in self.term_frequencies.items()}
    
    def calculate_weights(self):
        """–ò–∑—á–∏—Å–ª—è–≤–∞ —Ç–µ–≥–ª–∞ –∑–∞ —Ç–µ—Ä–º–∏–Ω–∏—Ç–µ —Å–ø–æ—Ä–µ–¥ —á–µ—Å—Ç–æ—Ç–∞—Ç–∞ –∏–º."""
        for term_type in ["positive", "negative", "neutral"]:
            frequencies = self.term_frequencies[term_type]
            if not frequencies:
                continue
                
            # –ù–∞–º–∏—Ä–∞–º–µ –º–∞–∫—Å–∏–º–∞–ª–Ω–∞—Ç–∞ —á–µ—Å—Ç–æ—Ç–∞ –∑–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            max_freq = max(frequencies.values())
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞–º–µ —Ç–µ–≥–ª–∞—Ç–∞ (0.1 –¥–æ 1.0) —Å–ø–æ—Ä–µ–¥ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª–Ω–∞—Ç–∞ —á–µ—Å—Ç–æ—Ç–∞
            self.term_weights[term_type] = {
                term: 0.1 + 0.9 * (freq / max_freq)
                for term, freq in frequencies.items()
            }
            
    def get_term_weight(self, term: str) -> Tuple[str, float]:
        """–í—Ä—ä—â–∞ —Ç–∏–ø–∞ –∏ —Ç–µ–≥–ª–æ—Ç–æ –Ω–∞ –¥–∞–¥–µ–Ω —Ç–µ—Ä–º–∏–Ω."""
        term = term.lower()
        term_type = self._get_term_type(term)
        if term_type:
            return term_type, self.term_weights[term_type].get(term, 0.1)
        return None, 0.0
    
    def process_documents(self):
        """–û–±—Ä–∞–±–æ—Ç–≤–∞ –≤—Å–∏—á–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –∏ –∏–∑–≤–ª–∏—á–∞/–∏–∑—á–∏—Å–ª—è–≤–∞ —Ç–µ–≥–ª–∞ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∏—Ç–µ."""
        print("üìä –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ —á–µ—Å—Ç–æ—Ç–∏ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∏—Ç–µ...")
        
        # –û–±—Ä–∞–±–æ—Ç–≤–∞–º–µ –≤—Å–∏—á–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏
        clean_dir = Path(CLEAN_DIR)
        for file in clean_dir.glob("*.txt"):
            text = read_text_file(file)
            print(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ {file.name}...")
            self.extract_terms(text)
            
        # –ò–∑—á–∏—Å–ª—è–≤–∞–º–µ —Ç–µ–≥–ª–∞—Ç–∞
        print("‚öñÔ∏è –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ —Ç–µ–≥–ª–∞...")
        self.calculate_weights()
        
        # –ó–∞–ø–∏—Å–≤–∞–º–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        results = {
            "frequencies": self.term_frequencies,
            "weights": self.term_weights
        }
        
        out_dir = Path(RESULTS_DIR)
        out_path = out_dir / "term_weights.json"
        write_json_file(results, out_path)
        print(f"‚úÖ –¢–µ–≥–ª–∞—Ç–∞ —Å–∞ –∑–∞–ø–∏—Å–∞–Ω–∏ –≤ {out_path}")
        
        return results


def main():
    extractor = TermWeightExtractor()
    extractor.process_documents()
    

if __name__ == "__main__":
    main()