import json
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple

from config import RESULTS_DIR
from utils.file_manager import write_json_file
from modules_extractors.term_weight_extractor import TermWeightExtractor
from modules_extractors.context_analyzer import ContextAnalyzer


class ScenarioAnalyzer:
    """–ö–ª–∞—Å –∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ —Ç–µ–≥–ª–∞ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∏—Ç–µ."""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."""
        self.term_extractor = TermWeightExtractor()
        self.context_analyzer = ContextAnalyzer()
        
        # –ü—ä—Ä–≤–æ –∏–∑–≤–ª–∏—á–∞–º–µ –∏ –∏–∑—á–∏—Å–ª—è–≤–∞–º–µ —Ç–µ–≥–ª–∞—Ç–∞ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∏—Ç–µ –æ—Ç –≤—Å–∏—á–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏
        print("üîÑ –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ —Ç–µ–≥–ª–∞ –Ω–∞ —Ç–µ—Ä–º–∏–Ω–∏—Ç–µ...")
        self.term_extractor.process_documents()
        
    def analyze_weighted_sentiment(self, text: str) -> Dict[str, dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–∞ –µ–º–æ—Ü–∏–æ–Ω–∞–ª–Ω–∞—Ç–∞ –æ–∫—Ä–∞—Å–∫–∞ –Ω–∞ —Ç–µ–∫—Å—Ç, –∏–∑–ø–æ–ª–∑–≤–∞–π–∫–∏ —Ç–µ–≥–ª–∞."""
        text = text.lower()
        sentiment_scores = {
            "positive": {"terms": [], "total_weight": 0.0},
            "negative": {"terms": [], "total_weight": 0.0},
            "neutral": {"terms": [], "total_weight": 0.0}
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –∑–∞ –≤—Å–∏—á–∫–∏ –≤—ä–∑–º–æ–∂–Ω–∏ —Ç–µ—Ä–º–∏–Ω–∏
        for term_set in [self.term_extractor.positive_terms,
                        self.term_extractor.negative_terms,
                        self.term_extractor.neutral_terms]:
            for term in term_set:
                if term in text:
                    term_type, weight = self.term_extractor.get_term_weight(term)
                    if term_type:
                        sentiment_scores[term_type]["terms"].append({
                            "term": term,
                            "weight": weight
                        })
                        sentiment_scores[term_type]["total_weight"] += weight
                        
        return sentiment_scores
    
    def get_dominant_sentiment(self, sentiment_scores: Dict[str, dict]) -> Tuple[str, float]:
        """–û–ø—Ä–µ–¥–µ–ª—è –¥–æ–º–∏–Ω–∏—Ä–∞—â–∏—è —Å–∞–Ω—Ç–∏–º–µ–Ω—Ç —Å–ø–æ—Ä–µ–¥ —Ç–µ–≥–ª–∞—Ç–∞."""
        max_weight = 0.0
        dominant_type = "neutral"
        
        for sent_type, data in sentiment_scores.items():
            if data["total_weight"] > max_weight:
                max_weight = data["total_weight"]
                dominant_type = sent_type
                
        return dominant_type, max_weight
    
    def analyze_scenario(self, scenario: dict) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–∞ –µ–¥–∏–Ω —Å—Ü–µ–Ω–∞—Ä–∏–π, –¥–æ–±–∞–≤—è–π–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ —Ç–µ–≥–ª–∞."""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Ç–µ–≥–ª–∞—Ç–∞ –∑–∞ —Ü—è–ª–æ—Ç–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ
        sentence_sentiment = self.analyze_weighted_sentiment(scenario["sentence"])
        sentence_context = self.context_analyzer.analyze_sentence_context(scenario["sentence"])
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Ç–µ–≥–ª–∞—Ç–∞ —Å–∞–º–æ –∑–∞ —Ñ—Ä–∞–∑–∞—Ç–∞ —Å –¥–µ–π—Å—Ç–≤–∏–µ—Ç–æ
        action_sentiment = self.analyze_weighted_sentiment(scenario["action_phrase"])
        action_context = self.context_analyzer.analyze_sentence_context(scenario["action_phrase"])
        
        # –û–ø—Ä–µ–¥–µ–ª—è–º–µ –¥–æ–º–∏–Ω–∏—Ä–∞—â–∏—Ç–µ —Ç–∏–ø–æ–≤–µ
        dominant_sentiment, sentiment_weight = self.get_dominant_sentiment(sentence_sentiment)
        dominant_context, _ = self.context_analyzer.get_dominant_context(sentence_context)
        
        # –°—ä–∑–¥–∞–≤–∞–º–µ –æ–±–æ–≥–∞—Ç–µ–Ω –∞–Ω–∞–ª–∏–∑
        enriched_analysis = {
            "context_analysis": {
                "sentence": {
                    "context": sentence_context,
                    "sentiment": sentence_sentiment
                },
                "action": {
                    "context": action_context,
                    "sentiment": action_sentiment
                },
                "dominant_context": dominant_context,
                "dominant_sentiment": {
                    "type": dominant_sentiment,
                    "weight": sentiment_weight
                }
            }
        }
        
        # –û–±–µ–¥–∏–Ω—è–≤–∞–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–π —Å –Ω–æ–≤–∏—è –∞–Ω–∞–ª–∏–∑
        return {**scenario, **enriched_analysis}
    
    def process_scenarios_file(self, file_path: Path):
        """–û–±—Ä–∞–±–æ—Ç–≤–∞ —Ñ–∞–π–ª —Å—ä—Å —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏ –¥–æ–±–∞–≤—è –æ–±–æ–≥–∞—Ç–µ–Ω –∞–Ω–∞–ª–∏–∑."""
        print(f"üìÑ –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –æ—Ç {file_path.name}...")
        
        # –ó–∞—Ä–µ–∂–¥–∞–º–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏—Ç–µ
        with open(file_path, "r", encoding="utf-8") as f:
            scenarios_data = json.load(f)
            
        # –û–±—Ä–∞–±–æ—Ç–≤–∞–º–µ –≤—Å–µ–∫–∏ —Å—Ü–µ–Ω–∞—Ä–∏–π
        enriched_scenarios = {}
        for actor, scenarios in scenarios_data.items():
            enriched_scenarios[actor] = [
                self.analyze_scenario(scenario)
                for scenario in scenarios
            ]
            
        # –ó–∞–ø–∏—Å–≤–∞–º–µ –æ–±–æ–≥–∞—Ç–µ–Ω–∏—Ç–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        write_json_file(enriched_scenarios, file_path)
        print(f"‚úÖ –û–±–æ–≥–∞—Ç–µ–Ω–∏—Ç–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å–∞ –∑–∞–ø–∏—Å–∞–Ω–∏ –≤ {file_path}")
        
    def process_all_scenarios(self):
        """–û–±—Ä–∞–±–æ—Ç–≤–∞ –≤—Å–∏—á–∫–∏ –Ω–∞–ª–∏—á–Ω–∏ —Ñ–∞–π–ª–æ–≤–µ —Å—ä—Å —Å—Ü–µ–Ω–∞—Ä–∏–∏."""
        scenarios_dir = Path(RESULTS_DIR) / "scenarios"
        for file in scenarios_dir.glob("*_scenarios.json"):
            self.process_scenarios_file(file)


def main():
    analyzer = ScenarioAnalyzer()
    analyzer.process_all_scenarios()
    

if __name__ == "__main__":
    main()