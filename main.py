# main.py
import scripts.clean_texts as clean_texts
import sys
import json
from pathlib import Path
from modules_extractors.entity_extractor import process_all_files as extract_entities


def main():
    """ÐŸÑŠÐ»ÐµÐ½ Ð¿Ñ€Ð¾Ñ†ÐµÑ: Ð¿Ð¾Ñ‡Ð¸ÑÑ‚Ð²Ð°Ð½Ðµ -> ÐµÐ½Ñ‚Ð¸Ñ‚ÐµÑ‚Ð¸ -> Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ -> ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¸ -> ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°"""
    print("ðŸŽ¯ Starting Complete National Security Analysis Pipeline")
    print("=" * 50)

    try:
        # Ð¡Ñ‚ÑŠÐ¿ÐºÐ° 1: ÐŸÐ¾Ñ‡Ð¸ÑÑ‚Ð²Ð°Ð½Ðµ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ðµ
        print("ðŸ“ Step 1: Cleaning texts...")
        clean_texts.process_files()

        # Ð¡Ñ‚ÑŠÐ¿ÐºÐ° 2: Ð˜Ð·Ð²Ð»Ð¸Ñ‡Ð°Ð½Ðµ Ð½Ð° ÐµÐ½Ñ‚Ð¸Ñ‚ÐµÑ‚Ð¸
        print("ðŸ·ï¸ Step 2: Extracting entities...")
        from modules_extractors.entity_extractor import process_all_files as extract_entities
        extract_entities()

        # Ð¡Ñ‚ÑŠÐ¿ÐºÐ° 3: Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð·Ð° ÐµÐ½Ñ‚Ð¸Ñ‚ÐµÑ‚Ð¸Ñ‚Ðµ
        print("ðŸ“Š Step 3: Analyzing entity frequencies...")
        from modules_extractors.entity_frequency_extractor import EntityFrequencyExtractor
        freq_extractor = EntityFrequencyExtractor()
        freq_extractor.process_entity_files()
        freq_extractor.save_results()

        # Ð¡Ñ‚ÑŠÐ¿ÐºÐ° 4: Ð˜Ð·Ð²Ð»Ð¸Ñ‡Ð°Ð½Ðµ Ð½Ð° Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ (FIXED)
        print("ðŸ”— Step 4: Extracting relations...")
        try:
            # ÐŸÑ€Ð¾Ð±Ð²Ð°Ð¹ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð½Ð¾Ñ‚Ð¾ Ð¸Ð¼Ðµ
            from modules_extractors.relations_extractor import process_all_files as extract_relations
            extract_relations()
        except ImportError:
            # ÐÐºÐ¾ Ð¿Ð°Ðº Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð¸, Ð¿ÑƒÑÐ½Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð½Ð¾
            print("  Using direct execution...")
            import subprocess
            subprocess.run([sys.executable, "-m", "modules_extractors.relations_extractor"])

        # Ð¡Ñ‚ÑŠÐ¿ÐºÐ° 5: Ð˜Ð·Ð²Ð»Ð¸Ñ‡Ð°Ð½Ðµ Ð½Ð° ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¸
        print("ðŸŽ­ Step 5: Extracting scenarios...")
        extract_scenarios()

        print("âœ… Analysis Complete! Check the 'data/annotated' folder for results.")

    except Exception as e:
        print(f"âŒ Error in pipeline: {e}")
        import traceback
        traceback.print_exc()


def extract_scenarios():
    """Ð˜Ð·Ð²Ð»Ð¸Ñ‡Ð°Ð½Ðµ Ð½Ð° ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¸ Ð·Ð° Ð²ÑÐ¸Ñ‡ÐºÐ¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¸"""
    from modules_extractors.scenario_extractor import ScenarioExtractor
    from config import CLEAN_DIR

    print("Starting scenario extraction for all documents...")
    try:
        extractor = ScenarioExtractor()
        clean_dir = Path(CLEAN_DIR)

        for doc_path in clean_dir.glob("*.txt"):
            print(f"Processing: {doc_path.name}")

            with open(doc_path, 'r', encoding='utf-8') as f:
                text = f.read()

            scenarios = extractor.extract_scenarios(text)
            sentiment = extractor.analyze_context_sentiment(text)

            output = {
                "file": doc_path.name,
                "total_scenarios": len(scenarios),
                "context_sentiment": sentiment,
                "scenarios": scenarios
            }

            output_file = Path("data/annotated/scenarios") / f"{doc_path.stem}_scenarios.json"
            output_file.parent.mkdir(parents=True, exist_ok=True)

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output, f, indent=2, ensure_ascii=False)

            print(f"  Extracted {len(scenarios)} scenarios -> {output_file}")

    except Exception as e:
        print(f"Error in scenario extraction: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "extract_scenarios":
        extract_scenarios()
    else:
        main()